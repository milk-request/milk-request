import requests
import re

def parse_url(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'
    }
    response = requests.get(url=url, headers=headers)
    text = response.text
    titles = re.findall(r'<div class="cont">.*?<b>(.*?)</b>',text,re.DOTALL)
    dynasties  = re.findall(r'<p class="source">.*?<a href=.*?>(.*?)</a>',text,re.DOTALL)
    authors =  re.findall(r'<p class="source">.*?<a href=.*?>.*?<a.*?>(.*?)</a>',text,re.DOTALL)
    content_tags = re.findall(r'<div class="contson".*?>(.*?)</div>',text,re.DOTALL)
    contents = []
    for content in content_tags:
        # print(content)
        x = re.sub(r'<.*?>','',content)#替换标签
        contents.append(x.strip())
    poems = []
    for view in zip(titles,dynasties,authors,contents):
        title,dynasty,author,content = view
        poem = {
            'title':title,
            'dynasty':dynasty,
            'author':author,
            'content':content
        }
        poems.append(poem)
    print(poems)
def spyder():
    for x in range(1,11):
        url = 'https://www.gushiwen.org/default_%s.aspx'%x
        parse_url(url)

if __name__ == '__main__':
    spyder()
