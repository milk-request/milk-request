import requests
from lxml import etree

BASE_url = 'https://www.ygdy8.net/'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'
}


def get_detail_urls(url):#获取页面里的url
    response = requests.get(url=url, headers=headers)
    # response.text解码方式是uncode
    # response.content可以指定解码方式
    text = response.text
    html = etree.HTML(text)
    detail_urls = html.xpath("//table[@class='tbspan']//a/@href")
    detail_urls = map(lambda url: BASE_url +url, detail_urls)  # lambda一个没有名字的函数，返回什么就写在冒号后面。再传入一个列表，遍历列表
    return detail_urls
def parse_info(info,rule):#替换不需要的词和空白
    return info.replace(rule,'').strip()
def parse_detail_page(url):#页面信息
    movie = {}
    response = requests.get(url,headers=headers)
    text = response.content.decode('gbk')
    html  = etree.HTML(text)
    title  = html.xpath(".//div[@class='title_all']//font[@color='#07519a']/text()")[0]
    movie['title'] = title
    cover = html.xpath("//div[@id='Zoom']//img/@src")
    if len(cover)==0:
        movie['cover']='false'
    else:
        movie['cover']=cover[0]
    infos = html.xpath("//div[@id='Zoom']//text()")
    for index,info in enumerate(infos):#索引和内容
        # print(index)
        # print(info)
        # print('=='*20)
        if info.startswith('◎年　　代'):
            info = parse_info(info,'◎年　　代')
            movie['year'] = info
        elif info.startswith('◎产　　地'):
            info =parse_info(info,'◎产　　地')
            movie['contury'] = info
        elif info.startswith('◎类　　别'):
            info =parse_info(info,'◎类　　别')
            movie['contury'] = info
        elif info.startswith('◎豆瓣评分'):
            info =parse_info(info,'◎豆瓣评分')
            movie['doban_rating'] = info
        elif info.startswith('◎片　　长'):
            info =parse_info(info,'◎片　　长')
            movie['duration'] = info
        elif info.startswith('◎导　　演'):
            info =parse_info(info,'◎导　　演')
            movie['director'] = info
        elif info.startswith('◎主　　演'):
            info =parse_info(info,'◎主　　演')
            actors=[info]
            for x in range(index+1,len(infos)):
                actor = infos[x].strip()
                actors.append(actor)
                if actor.startswith('◎'):
                    break
                actors.append(actor)

            movie['actors']=actors
        elif info.startswith('◎简　　介'):
            info = parse_info(info, '◎简　　介')
            for x in range(index+1,len(infos)):
                profile = infos[x].strip()
                if profile.startswith('【下载地址】'):
                    break
                movie['profile']=profile
    download_url=html.xpath("//td[@bgcolor='#fdfddf']/a/text()")[0]
    movie['download_url']=download_url
    return movie







def spyder():
    baseurl = 'https://www.ygdy8.net/html/gndy/dyzz/list_23_{}.html'
    movies=[]
    for x in range(1,8):#第一个for循环总共有7页
        url = baseurl.format(x)
        detalis_urls = get_detail_urls(url)
        for detalis_url in detalis_urls:#第二个for循环 遍历每一页中的所有电影详情url
           movie=parse_detail_page(detalis_url)
           movies.append(movie)
           print(movies)

if __name__ == '__main__':
    spyder()

# 2.请求每一页的url,获取数据
